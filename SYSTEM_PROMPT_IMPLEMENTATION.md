# ‚úÖ Implementa√ß√£o de System Prompt para An√°lises Forenses

## üéØ Objetivo

Adicionar suporte a **system prompt** (system_instruction) separado do prompt de conte√∫do, permitindo melhor controle sobre o comportamento da LLM nas 9 an√°lises forenses.

## üìã Motiva√ß√£o

**Antes:** Todo o contexto (instru√ß√µes do sistema + tarefa espec√≠fica) estava em um √∫nico campo `prompt_content`.

**Problema:**
- Mistura de instru√ß√µes gerais com instru√ß√µes espec√≠ficas
- Dif√≠cil ajustar comportamento global sem modificar cada prompt
- N√£o aproveitava o padr√£o `systemInstruction` do Gemini API

**Agora:** Separa√ß√£o clara:
- `system_prompt`: Instru√ß√µes fundamentais sobre o papel e comportamento da IA
- `prompt_content`: Instru√ß√µes espec√≠ficas da tarefa de an√°lise

---

## üóÑÔ∏è Mudan√ßas no Banco de Dados

### 1. Tabela `analysis_prompts`

**Migration:** `add_system_prompt_to_analysis_prompts.sql`

```sql
ALTER TABLE analysis_prompts
ADD COLUMN IF NOT EXISTS system_prompt TEXT;

COMMENT ON COLUMN analysis_prompts.system_prompt IS 
'Instru√ß√µes fundamentais do sistema enviadas como system_instruction para a LLM. Define o papel, comportamento e diretrizes gerais da IA para esta an√°lise espec√≠fica.';
```

### 2. Fun√ß√£o `acquire_next_prompt_lock`

**Migration:** `add_system_prompt_to_acquire_lock_function.sql`

Atualizada para retornar `system_prompt` junto com `prompt_content`:

```sql
CREATE OR REPLACE FUNCTION acquire_next_prompt_lock(...)
RETURNS TABLE (
  ...
  prompt_content text,
  system_prompt text,  -- ‚úÖ NOVO
  ...
)
```

---

## üíª Mudan√ßas no Frontend

### 1. Service (`AnalysisPromptsService.ts`)

**Interface atualizada:**
```typescript
export interface AnalysisPrompt {
  id: string;
  title: string;
  prompt_content: string;
  system_prompt?: string | null;  // ‚úÖ NOVO
  execution_order: number;
  is_active: boolean;
  created_at: string;
  updated_at: string;
}
```

**M√©todos atualizados:**
```typescript
static async createPrompt(
  title: string,
  promptContent: string,
  executionOrder: number,
  systemPrompt?: string  // ‚úÖ NOVO
)

static async updatePrompt(
  promptId: string,
  title: string,
  promptContent: string,
  executionOrder: number,
  systemPrompt?: string  // ‚úÖ NOVO
)
```

### 2. Interface Admin (`AdminForensicPromptsPage.tsx`)

**Form Data:**
```typescript
const [formData, setFormData] = useState({
  execution_order: 1,
  title: '',
  prompt_content: '',
  system_prompt: ''  // ‚úÖ NOVO
});
```

**Novo Campo no Formul√°rio:**
```tsx
<div className="w-full max-w-full">
  <label>System Prompt (Opcional)</label>
  <textarea
    value={formData.system_prompt}
    onChange={(e) => setFormData({ ...formData, system_prompt: e.target.value })}
    rows={6}
    placeholder="Instru√ß√µes fundamentais do sistema (ex: Voc√™ √© um especialista jur√≠dico...)"
  />
  <p>
    {formData.system_prompt.length} caracteres ‚Ä¢ Define o papel e comportamento da IA
  </p>
</div>
```

**Visualiza√ß√£o Expandida:**
```tsx
{prompt.system_prompt && (
  <div className="mb-4">
    <h4>System Prompt:</h4>
    <pre>{prompt.system_prompt}</pre>
    <p>{prompt.system_prompt.length} caracteres ‚Ä¢ Enviado como system_instruction</p>
  </div>
)}
```

---

## ‚öôÔ∏è Mudan√ßas nas Edge Functions

### 1. `process-next-prompt/index.ts`

**3 locais de chamada do Gemini atualizados:**

#### A. Chunk Processing (arquivos grandes):
```typescript
const chunkResult = await geminiModel.generateContent({
  contents: [{ role: 'user', parts: chunkParts }],
  systemInstruction: nextResult.system_prompt || undefined,  // ‚úÖ NOVO
  generationConfig: {
    temperature,
    maxOutputTokens: maxTokens,
  },
});
```

#### B. File API (arquivos m√©dios):
```typescript
const result = await geminiModel.generateContent({
  contents: [{ role: 'user', parts }],
  systemInstruction: nextResult.system_prompt || undefined,  // ‚úÖ NOVO
  generationConfig: {
    temperature,
    maxOutputTokens: maxTokens,
  },
});
```

#### C. Base64 Inline (arquivos pequenos):
```typescript
const result = await geminiModel.generateContent({
  contents: [
    {
      role: 'user',
      parts: [
        {
          inlineData: {
            mimeType: 'application/pdf',
            data: base64Data,
          },
        },
        { text: nextResult.prompt_content },
      ],
    },
  ],
  systemInstruction: nextResult.system_prompt || undefined,  // ‚úÖ NOVO
  generationConfig: {
    temperature,
    maxOutputTokens: maxTokens,
  },
});
```

### 2. `consolidation-worker/index.ts`

**SELECT atualizado:**
```typescript
.select('id, prompt_id, prompt_title, prompt_content, system_prompt, execution_order, status')  // ‚úÖ system_prompt adicionado
```

**Chamada do Gemini:**
```typescript
const result = await geminiModel.generateContent({
  contents: [{ role: 'user', parts: [{ text: consolidationPrompt }] }],
  systemInstruction: analysisResult.system_prompt || undefined,  // ‚úÖ NOVO
  generationConfig: {
    temperature: 0.1,
    maxOutputTokens: model.maxTokens,
  },
});
```

---

## üìä Como Usar

### 1. Na Interface Admin

1. Acesse **Admin > Prompts Forenses**
2. Clique em um prompt para editar
3. Preencha o campo **"System Prompt (Opcional)"**
4. Salve

### 2. Exemplo de System Prompt

```
Voc√™ √© um Perito Jur√≠dico Processual especializado em an√°lise t√©cnico-documental e reconstru√ß√£o de autos, com dom√≠nio em Direito Material e Processual C√≠vel, Trabalhista e Tribut√°rio.

DIRETRIZES FUNDAMENTAIS:
1. Seja preciso e t√©cnico nas an√°lises
2. Cite sempre as fontes (p√°ginas e documentos)
3. Use linguagem jur√≠dica apropriada
4. Mantenha imparcialidade absoluta
5. Fundamente todas as conclus√µes em dados concretos do processo

IMPORTANTE:
- NUNCA invente informa√ß√µes
- SEMPRE indique "N√£o identificado" se n√£o encontrar dados
- Mantenha estrutura JSON rigorosa
- Priorize clareza e utilidade pr√°tica para advogados
```

### 3. Exemplo de Prompt Content

```
1. Vis√£o Geral do Processo

Voc√™ √© um Perito Jur√≠dico Processual especializado...

Sua miss√£o nesta etapa √© realizar uma an√°lise t√©cnica...

CONTEXTO E OBJETIVO DESTA ETAPA
Esta √© a Etapa 1 de 9 da an√°lise completa dos autos...

[... resto do prompt espec√≠fico da tarefa ...]
```

---

## üîç Fluxo Completo

### 1. Admin Cadastra/Edita Prompt
```
Admin Interface ‚Üí AnalysisPromptsService.updatePrompt() ‚Üí 
database.analysis_prompts.update(system_prompt)
```

### 2. Processo Inicia An√°lise
```
start-analysis ‚Üí cria 9 analysis_results com prompt_content + system_prompt copiados
```

### 3. Worker Processa Prompt
```
process-next-prompt ‚Üí acquire_next_prompt_lock() ‚Üí retorna system_prompt + prompt_content
```

### 4. Chamada para Gemini
```typescript
geminiModel.generateContent({
  systemInstruction: system_prompt,  // Instru√ß√µes gerais
  contents: [{
    role: 'user',
    parts: [{ text: prompt_content }]  // Tarefa espec√≠fica
  }]
})
```

### 5. Consolida√ß√£o (Arquivos Grandes)
```
consolidation-worker ‚Üí busca system_prompt do analysis_result ‚Üí 
envia junto com consolidationPrompt
```

---

## ‚úÖ Benef√≠cios da Implementa√ß√£o

### 1. Separa√ß√£o de Responsabilidades
- **System Prompt:** "Quem voc√™ √©" e "como voc√™ deve agir"
- **Prompt Content:** "O que voc√™ deve fazer"

### 2. Facilidade de Ajuste
- Alterar comportamento global? ‚Üí Editar system_prompt
- Ajustar tarefa espec√≠fica? ‚Üí Editar prompt_content
- Sem necessidade de modificar ambos

### 3. Melhor Controle da LLM
- System instruction tem maior "peso" na API do Gemini
- Define personalidade consistente ao longo da conversa
- Reduz chance de "drift" no comportamento

### 4. Reutiliza√ß√£o
- Mesmo system_prompt pode ser usado em v√°rios prompts
- Exemplo: Todos os 9 prompts podem compartilhar as diretrizes fundamentais
- Cada um tem seu prompt_content espec√≠fico

### 5. Conformidade com Best Practices
- Segue o padr√£o recomendado pela Google/Gemini API
- Aproveitamelhor os recursos da LLM
- Resulta em outputs mais consistentes

---

## üìù Status da Implementa√ß√£o

### ‚úÖ Completo

1. ‚úÖ Migration do banco de dados
2. ‚úÖ Atualiza√ß√£o da fun√ß√£o `acquire_next_prompt_lock`
3. ‚úÖ Interface Service (`AnalysisPromptsService`)
4. ‚úÖ Interface Admin (`AdminForensicPromptsPage`)
5. ‚úÖ Edge function `process-next-prompt` (3 locais)
6. ‚úÖ Edge function `consolidation-worker`
7. ‚úÖ Build do frontend
8. ‚úÖ Documenta√ß√£o completa

### ‚è≥ Pendente de Deploy

**Edge Functions precisam ser deployadas manualmente:**

```bash
# Deploy process-next-prompt
supabase functions deploy process-next-prompt --no-verify-jwt

# Deploy consolidation-worker
supabase functions deploy consolidation-worker --no-verify-jwt
```

**Nota:** Os arquivos j√° est√£o atualizados no reposit√≥rio, apenas aguardando deploy.

### üìã Pr√≥ximos Passos Sugeridos

1. **Deploy das Edge Functions** (manual via Supabase CLI)
2. **Criar System Prompts Padr√£o** para os 9 prompts existentes
3. **Testar** com um processo real
4. **Documentar Boas Pr√°ticas** para cria√ß√£o de system prompts

---

## üéØ Exemplo de Uso Completo

### Prompt 1: Vis√£o Geral do Processo

**System Prompt:**
```
Voc√™ √© um Perito Jur√≠dico especializado em an√°lise processual.

IDENTIDADE:
- Expert em reconstru√ß√£o de autos
- Dom√≠nio em Direito Processual C√≠vel, Trabalhista e Tribut√°rio
- Analista t√©cnico-documental certificado

COMPORTAMENTO:
1. Precis√£o t√©cnica absoluta
2. Fundamenta√ß√£o em dados concretos
3. Imparcialidade total
4. Clareza e objetividade

FORMATO:
- Sempre retorne JSON v√°lido
- Cite p√°ginas e documentos
- Use "N√£o identificado" quando n√£o houver dados
- Mantenha hierarquia estruturada
```

**Prompt Content:**
```
1. Vis√£o Geral do Processo

Sua miss√£o √© extrair e organizar dados essenciais:
- Dados do processo (n√∫mero, vara, inst√¢ncia)
- Partes envolvidas
- Linha do tempo
- Fase processual
- Documentos analisados

[... instru√ß√µes espec√≠ficas da tarefa ...]
```

**Resultado:**
- LLM recebe contexto claro de quem ela √© (system_prompt)
- Recebe instru√ß√µes espec√≠ficas do que fazer (prompt_content)
- Gera an√°lise consistente com a "personalidade" definida

---

## üîß Troubleshooting

### System Prompt n√£o est√° sendo usado?

1. Verificar se edge function foi deployada:
   ```bash
   curl -X POST "${SUPABASE_URL}/functions/v1/process-next-prompt" ...
   # Verificar nos logs do Supabase se system_prompt est√° presente
   ```

2. Verificar se prompt tem system_prompt cadastrado:
   ```sql
   SELECT id, title, system_prompt IS NOT NULL as has_system_prompt
   FROM analysis_prompts
   ORDER BY execution_order;
   ```

3. Verificar se an√°lise copiou o system_prompt:
   ```sql
   SELECT id, prompt_title, system_prompt IS NOT NULL as has_system_prompt
   FROM analysis_results
   WHERE processo_id = '<processo-id>'
   ORDER BY execution_order;
   ```

### An√°lise retorna erro "systemInstruction is not defined"?

- Vers√£o antiga do `@google/generative-ai`
- Atualizar para vers√£o >= 0.24.1:
  ```typescript
  import { GoogleGenerativeAI } from 'npm:@google/generative-ai@0.24.1';
  ```

---

## üìö Refer√™ncias

- [Gemini API - System Instructions](https://ai.google.dev/gemini-api/docs/system-instructions)
- [Best Practices for Prompting](https://ai.google.dev/gemini-api/docs/prompting-strategies)
- [Separating System vs User Content](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/design-prompts)

---

## ‚úÖ Conclus√£o

Sistema completo de **system prompt separado** implementado com sucesso!

**Benef√≠cios:**
- ‚úÖ Melhor controle sobre comportamento da LLM
- ‚úÖ Facilidade de ajuste e manuten√ß√£o
- ‚úÖ Conformidade com best practices
- ‚úÖ Reutiliza√ß√£o de instru√ß√µes gerais
- ‚úÖ Outputs mais consistentes

**Pr√≥ximo Passo:** Deploy das edge functions e cria√ß√£o dos system prompts padr√£o para os 9 prompts forenses.
